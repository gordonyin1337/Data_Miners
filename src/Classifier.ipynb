{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "train_data_dir = 'C:\\MinecraftFiles' #replace this with your own directory for pictures\n",
    "nb_train_samples = 2400\n",
    "nb_validation_samples = 800\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 4 classes.\n",
      "Found 800 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#reads images in from the directory, the \"subset\" parameters automatically splits the data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle = 'true')  \n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the parameters we could try changing to get better results, things such as adding additional convolution layers.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "150/150 [==============================] - 97s 648ms/step - loss: 1.0559 - acc: 0.4583 - val_loss: 0.8227 - val_acc: 0.5625\n",
      "Epoch 2/75\n",
      "150/150 [==============================] - 82s 548ms/step - loss: 0.8554 - acc: 0.5337 - val_loss: 0.7978 - val_acc: 0.5513\n",
      "Epoch 3/75\n",
      "150/150 [==============================] - 80s 537ms/step - loss: 0.8034 - acc: 0.5942 - val_loss: 0.7970 - val_acc: 0.5463\n",
      "Epoch 4/75\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.7650 - acc: 0.6008 - val_loss: 0.7816 - val_acc: 0.5787\n",
      "Epoch 5/75\n",
      "150/150 [==============================] - 80s 537ms/step - loss: 0.7402 - acc: 0.6033 - val_loss: 0.8497 - val_acc: 0.5038\n",
      "Epoch 6/75\n",
      "150/150 [==============================] - 80s 533ms/step - loss: 0.7358 - acc: 0.6158 - val_loss: 0.8888 - val_acc: 0.5938\n",
      "Epoch 7/75\n",
      "150/150 [==============================] - 80s 536ms/step - loss: 0.7325 - acc: 0.6279 - val_loss: 0.7269 - val_acc: 0.5850\n",
      "Epoch 8/75\n",
      "150/150 [==============================] - 80s 536ms/step - loss: 0.7016 - acc: 0.6450 - val_loss: 0.7858 - val_acc: 0.6275\n",
      "Epoch 9/75\n",
      "150/150 [==============================] - 81s 539ms/step - loss: 0.6770 - acc: 0.6300 - val_loss: 0.7840 - val_acc: 0.6062\n",
      "Epoch 10/75\n",
      "150/150 [==============================] - 80s 534ms/step - loss: 0.6769 - acc: 0.6404 - val_loss: 1.0476 - val_acc: 0.5863\n",
      "Epoch 11/75\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.6538 - acc: 0.6562 - val_loss: 0.7827 - val_acc: 0.5962\n",
      "Epoch 12/75\n",
      "150/150 [==============================] - 80s 535ms/step - loss: 0.6540 - acc: 0.6804 - val_loss: 0.8075 - val_acc: 0.6225\n",
      "Epoch 13/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.6593 - acc: 0.6771 - val_loss: 0.7633 - val_acc: 0.6512\n",
      "Epoch 14/75\n",
      "150/150 [==============================] - 80s 534ms/step - loss: 0.6195 - acc: 0.6787 - val_loss: 0.7891 - val_acc: 0.6737\n",
      "Epoch 15/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.6330 - acc: 0.6846 - val_loss: 0.7287 - val_acc: 0.6388\n",
      "Epoch 16/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.6188 - acc: 0.6883 - val_loss: 0.8059 - val_acc: 0.6112\n",
      "Epoch 17/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.6114 - acc: 0.6933 - val_loss: 0.7865 - val_acc: 0.6725\n",
      "Epoch 18/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.5945 - acc: 0.7146 - val_loss: 0.8079 - val_acc: 0.6200\n",
      "Epoch 19/75\n",
      "150/150 [==============================] - 80s 535ms/step - loss: 0.5731 - acc: 0.7275 - val_loss: 0.7301 - val_acc: 0.6737\n",
      "Epoch 20/75\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.5654 - acc: 0.7350 - val_loss: 0.7523 - val_acc: 0.6850\n",
      "Epoch 21/75\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.5752 - acc: 0.7283 - val_loss: 0.7943 - val_acc: 0.6825\n",
      "Epoch 22/75\n",
      "150/150 [==============================] - 80s 536ms/step - loss: 0.5509 - acc: 0.7508 - val_loss: 0.9267 - val_acc: 0.6362\n",
      "Epoch 23/75\n",
      "150/150 [==============================] - 81s 543ms/step - loss: 0.5333 - acc: 0.7446 - val_loss: 0.7270 - val_acc: 0.7013\n",
      "Epoch 24/75\n",
      "150/150 [==============================] - 81s 541ms/step - loss: 0.5418 - acc: 0.7533 - val_loss: 0.8466 - val_acc: 0.6450\n",
      "Epoch 25/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.5263 - acc: 0.7542 - val_loss: 1.1198 - val_acc: 0.6088\n",
      "Epoch 26/75\n",
      "150/150 [==============================] - 80s 535ms/step - loss: 0.5332 - acc: 0.7567 - val_loss: 0.7695 - val_acc: 0.7225\n",
      "Epoch 27/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.5219 - acc: 0.7617 - val_loss: 0.8103 - val_acc: 0.6713\n",
      "Epoch 28/75\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.5157 - acc: 0.7721 - val_loss: 1.0927 - val_acc: 0.6050\n",
      "Epoch 29/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.5063 - acc: 0.7804 - val_loss: 0.9425 - val_acc: 0.6125\n",
      "Epoch 30/75\n",
      "150/150 [==============================] - 80s 537ms/step - loss: 0.5125 - acc: 0.7729 - val_loss: 0.7401 - val_acc: 0.7325\n",
      "Epoch 31/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.5073 - acc: 0.7796 - val_loss: 0.7674 - val_acc: 0.7163\n",
      "Epoch 32/75\n",
      "150/150 [==============================] - 80s 537ms/step - loss: 0.4796 - acc: 0.7946 - val_loss: 0.7518 - val_acc: 0.7612\n",
      "Epoch 33/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4804 - acc: 0.7921 - val_loss: 0.6744 - val_acc: 0.7388\n",
      "Epoch 34/75\n",
      "150/150 [==============================] - 81s 539ms/step - loss: 0.4723 - acc: 0.7983 - val_loss: 0.7059 - val_acc: 0.7050\n",
      "Epoch 35/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4598 - acc: 0.8075 - val_loss: 0.7408 - val_acc: 0.7288\n",
      "Epoch 36/75\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.4609 - acc: 0.8008 - val_loss: 0.7157 - val_acc: 0.7562\n",
      "Epoch 37/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4431 - acc: 0.8146 - val_loss: 0.7220 - val_acc: 0.7425\n",
      "Epoch 38/75\n",
      "150/150 [==============================] - 81s 542ms/step - loss: 0.4542 - acc: 0.8167 - val_loss: 0.7139 - val_acc: 0.7312\n",
      "Epoch 39/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4448 - acc: 0.8187 - val_loss: 0.7500 - val_acc: 0.7400\n",
      "Epoch 40/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4662 - acc: 0.8163 - val_loss: 0.7409 - val_acc: 0.7075\n",
      "Epoch 41/75\n",
      "150/150 [==============================] - 81s 539ms/step - loss: 0.4517 - acc: 0.8121 - val_loss: 0.8131 - val_acc: 0.7212\n",
      "Epoch 42/75\n",
      "150/150 [==============================] - 83s 552ms/step - loss: 0.4402 - acc: 0.8171 - val_loss: 0.7596 - val_acc: 0.7625\n",
      "Epoch 43/75\n",
      "150/150 [==============================] - 84s 558ms/step - loss: 0.4343 - acc: 0.8287 - val_loss: 0.7407 - val_acc: 0.7238\n",
      "Epoch 44/75\n",
      "150/150 [==============================] - 80s 536ms/step - loss: 0.4224 - acc: 0.8183 - val_loss: 1.1695 - val_acc: 0.6725\n",
      "Epoch 45/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4552 - acc: 0.8213 - val_loss: 1.4760 - val_acc: 0.6388\n",
      "Epoch 46/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4524 - acc: 0.8163 - val_loss: 0.6932 - val_acc: 0.7625\n",
      "Epoch 47/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4482 - acc: 0.8279 - val_loss: 0.6731 - val_acc: 0.7400\n",
      "Epoch 48/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.3870 - acc: 0.8304 - val_loss: 0.7297 - val_acc: 0.7825\n",
      "Epoch 49/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4493 - acc: 0.8304 - val_loss: 0.7472 - val_acc: 0.7462\n",
      "Epoch 50/75\n",
      "150/150 [==============================] - 80s 534ms/step - loss: 0.4571 - acc: 0.8317 - val_loss: 0.6904 - val_acc: 0.7925\n",
      "Epoch 51/75\n",
      "150/150 [==============================] - 81s 539ms/step - loss: 0.4050 - acc: 0.8392 - val_loss: 0.8876 - val_acc: 0.7612\n",
      "Epoch 52/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4410 - acc: 0.8337 - val_loss: 0.7773 - val_acc: 0.7688\n",
      "Epoch 53/75\n",
      "150/150 [==============================] - 81s 539ms/step - loss: 0.4267 - acc: 0.8404 - val_loss: 0.7531 - val_acc: 0.7850\n",
      "Epoch 54/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4406 - acc: 0.8404 - val_loss: 0.7701 - val_acc: 0.7300\n",
      "Epoch 55/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4099 - acc: 0.8350 - val_loss: 0.7868 - val_acc: 0.7400\n",
      "Epoch 56/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4107 - acc: 0.8413 - val_loss: 0.7929 - val_acc: 0.7338\n",
      "Epoch 57/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4163 - acc: 0.8408 - val_loss: 0.8397 - val_acc: 0.7538\n",
      "Epoch 58/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4346 - acc: 0.8400 - val_loss: 0.7357 - val_acc: 0.7625\n",
      "Epoch 59/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4412 - acc: 0.8312 - val_loss: 0.7579 - val_acc: 0.7675\n",
      "Epoch 60/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4039 - acc: 0.8467 - val_loss: 0.8370 - val_acc: 0.7087\n",
      "Epoch 61/75\n",
      "150/150 [==============================] - 80s 536ms/step - loss: 0.3931 - acc: 0.8438 - val_loss: 0.7700 - val_acc: 0.7525\n",
      "Epoch 62/75\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.4233 - acc: 0.8317 - val_loss: 0.8053 - val_acc: 0.7675\n",
      "Epoch 63/75\n",
      "150/150 [==============================] - 80s 536ms/step - loss: 0.4346 - acc: 0.8425 - val_loss: 0.7462 - val_acc: 0.7238\n",
      "Epoch 64/75\n",
      "150/150 [==============================] - 80s 537ms/step - loss: 0.4190 - acc: 0.8408 - val_loss: 0.7563 - val_acc: 0.7638\n",
      "Epoch 65/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4618 - acc: 0.8263 - val_loss: 0.5917 - val_acc: 0.7800\n",
      "Epoch 66/75\n",
      "150/150 [==============================] - 80s 535ms/step - loss: 0.3898 - acc: 0.8508 - val_loss: 1.2225 - val_acc: 0.7262\n",
      "Epoch 67/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4150 - acc: 0.8383 - val_loss: 0.7600 - val_acc: 0.7900\n",
      "Epoch 68/75\n",
      "150/150 [==============================] - 80s 534ms/step - loss: 0.4310 - acc: 0.8462 - val_loss: 0.6166 - val_acc: 0.7650\n",
      "Epoch 69/75\n",
      "150/150 [==============================] - 81s 537ms/step - loss: 0.4091 - acc: 0.8500 - val_loss: 0.7980 - val_acc: 0.7837\n",
      "Epoch 70/75\n",
      "150/150 [==============================] - 80s 535ms/step - loss: 0.4115 - acc: 0.8471 - val_loss: 0.9115 - val_acc: 0.7375\n",
      "Epoch 71/75\n",
      "150/150 [==============================] - 81s 539ms/step - loss: 0.4334 - acc: 0.8408 - val_loss: 0.6700 - val_acc: 0.7925\n",
      "Epoch 72/75\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 0.4012 - acc: 0.8408 - val_loss: 0.6833 - val_acc: 0.7575\n",
      "Epoch 73/75\n",
      "150/150 [==============================] - 80s 537ms/step - loss: 0.3944 - acc: 0.8508 - val_loss: 0.9875 - val_acc: 0.7225\n",
      "Epoch 74/75\n",
      "150/150 [==============================] - 80s 535ms/step - loss: 0.4370 - acc: 0.8483 - val_loss: 1.1054 - val_acc: 0.7075\n",
      "Epoch 75/75\n",
      "150/150 [==============================] - 81s 538ms/step - loss: 0.4410 - acc: 0.8283 - val_loss: 1.0239 - val_acc: 0.7612\n"
     ]
    }
   ],
   "source": [
    "H =model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2400 // batch_size,\n",
    "        epochs=75,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save('conv_network.h5')  #saves the model. once you have this file saved it's possible to open it somewhere else with keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-514b7087913c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ggplot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training Loss on Dataset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "N = 75\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
